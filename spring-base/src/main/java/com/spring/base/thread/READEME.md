# 1. 线程专业术语  
    
    非线程安全：非线程安全主要是指多个线程对同一个对象中的 同一个变量实例变量进行操作是会出现值被更改，值不同步的情况，进而影响程序的执行流程。
    
    在Java中有三种方法可以终止正在运行的线程：
      1.使用退出标志，使线程正常退出，也就是当run方法完成后线程终止。
      2.使用stop方法强行终止线程，但是不推荐使用这个方法，因为Stop和Susped及resume一样，都是过期作废的方法，使用它们可能产生不可预料的结果。
      3.使用interrupt方法中断线程，但是interrupt方法不像for-break的使用效果那么明显，马上就停止循环。调用interrupt方法仅仅是在当前线程中打了一个停止标记，并不是真的停止线程。
    
    yield()方法的作用是放弃当前的CPU资源，将它让给其他的任务去占用CPU执行时间。但是放弃的时间不确定，有可能刚刚放弃，马上又获得CPU时间片。
    非线程安全其实就算是多个线程对同一个对象中的实例变量进行并发访问时发生，产生的后果就是脏读，取到的数据是被改过得数据，而线程安全就是获得是实例变量的值经过同步处理的。
    
    
    某个线程中创建的新线程优先级与是否为守护线程，与创建的这个线程的线程属性一致。
    When code running in some thread creates a new <code>Thread</code> object, the new thread has its priority initially set equal to the priority 
    of the creating thread, and is a daemon thread if and only if the  creating thread is a daemon.
    
# 2. 非线程安全仅针对实例变量，对方法内部的变量不做比较，因为方法内部的变量是私有的。
    
    静态方法锁或者同步代码块指针对类，不针对实例变量，实例变量的锁和类的锁不是同一把锁
    简单来说，只要针对的不是同一实例变量，且加锁的对象不相同，程序就是异步运行，仅针对同步方法和同步代码块。
# 3. volatile关键字的作用是强制从公共堆栈中获取变量的值，而不是从线程私有数据栈中获取变量的值。
    volatile关键字的作用是使变量在多线程间可见。
    
    使用volatile关键字增加了实例变量在多个线程之间的可见性。但是volatile关键字最致命的缺点是不支持原子性:
      1.关键字volatile是线程同步的轻量级实现，所以volatile性能肯定比synchronized要好，并且volatile执行修饰变量，而synchronized
    可以修饰方法。以及代码块。随着JDK新版本的发布，synchronized关键字在执行效率上得到很大提升，在开发中使用synchronized的比率还是
    比较大的。
      2.多线程访问volatile不会发生阻塞，而synchronized会发生阻塞。
      3.volatile保证了数据的可见性，但不保证原子性。而synchronized可以保证原子性，也可以间接保证可见性。因为它会将私有内存和公共内存中
    的数据做同步。
      4.再次重申一次，关键字volatile是解决变量在多个线程之间的可见性。而synchronized关键字解决的是多个线程之间访问资源的同步性。
    线程安全包含原子性和可见性两个方面，Java的同步机制都是围绕这两个方面来确定线程安全的。
    
    如果对于测试的变量值count1,在测试方法中加了synchronized关键字，变量前面就不用加volatile关键字
    关键字volatile主要使用场合是在多个线程中可以感知实例变量被更改了，并且可以获得最新的值使用，也就是多线程读取
    共享变量时可以获取最新值使用。
    关键字volatie提示线程每次从共享内存中读取变量，而不是从私有内存中读取变量，这样就保证了同步数据的可见性。
    但在这里需要注意的是：如果实例变量中的数据，比如i++,也就是i+=1;这样的操作其实并不是一个原子操作，就是非线程安
    全的，表示i++的操作步骤分解如下：
      1.从内存中取出i的值。
      2.计算i的值。
      3.将i的值写到内存中。
    假如在第二步计算过程中，另外一个线程也修了i的值，这个时候就出现了脏读（脏读就是指当一个事务正在访问数据，并且对
    数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。因为这个数
    据是还没有提交的数据，那么另外一个事务读到的这个数据是脏数据，依据脏数据所做的操作可能是不正确的）。解决方法就是
    使用synchronized,所以volatile本身不处理数据的原子性，而是强制对数据的读写及时响应到主机内存中。
    
# 4. 线程池构建对象参数说明

参数 workQueue 值被提交但未执行的任务队列，她是一个 Blocking 接口的对象，仅用于存放 Runnable 对象。根据队列功能分类，在
ThreadPoolExecutor 类的构造函数汇总可使用以下几种 BlockingQueue 接口：

- 直接提交的队列：该功能有 SynchronousQueue 对象提供。SynchronousQueue 是一个特殊的 BlockingQueue.SynchronousQueue 
没有容量，每一个插入操作都要等待一个相应的删除操作，反之，每一个删除操作都要等待对应的插入操作。如果使用 SynchronousQueue ,
则提交的任务不会被真实地保存，而总是将新任务给线程执行，如果没有空闲的进程，则尝试创建新的进程，如果进程数量已经达到最大值，
则执行拒绝策略。因此，使用 SynchronosQueue 队列，通常要设置很大的 maximumPoolSize 值，否则很容易执行拒绝策略。
- 有界的任务队列：有界的任务队列可以使用 ArrayBlockQueue 类实现。ArrayBlockingQueue 类的构造函数必须带有一个容量的参数,
表示该队列的最大容量：public ArrayBlockingQueue(int capacity) 
    - **当使用有界的任务队列时，若有新的任务需要执行，如果线程池的实际线程数小于 corePoolSize,则会有限创建新的线程，若大于 
    corePoolSize ，则会将新任务加入等待队列。若等待队列已满，无法加入，则总线程数大于 maximumPoolSize 的前提下，创建新的
    进程执行任务。若大于 maximumPoolSize ，则执行拒绝策略**。可见，有界队列仅当在任务队列装满时，才可能将线程数提升到 corePoolSize
    以上，换言之，除非系统繁忙，否则要确保核心线程数维持在 corePoolSize.
- 无界的任务队列：无界任务队列可以通过 LinkedBlockingQueue 类实现。与有界队列相比，除非系统资源好近，否则无界的任务队列不存
在任务入队失败的情况。当有新的任务到来，系统的线程数小于 corePoolSize 是，线程池会生成新的线程执行任务，但当系统的线程数达到
corePoolSize 后，就不会继续增加了。若后续仍有新的任务加入，而又没有空闲的线程资源，则任务直接进入队列等待。若任务创建和处理的
速度差异很大，无界队列会保持快速增长，直到耗尽系统内存。
- 优先任务队列：优先任务队列是带有执行优先级的队列。它通过 PriorityBlockingQueue 类实现，可以控制任务的执行先后顺序。它是一个
特殊的无界队列。无论是有界队列 ArrayBlockingQueue 类，还是未指定大小的无界队列 LinkedBlockingQueue 类都是按照先进先出算法处理
任务的。而 PriorityBlockingQueue 类则可以根据任务自身的优先级顺序先后执行，在确保系统性能的同时，也能有很好的质量保证。

回顾 newFixedThreadPool() 方法的实现，它返回了一个 corePoolSize 和 maximumPoolSize 大小一样的，并且使用了 LinkedBlockingQueue
任务队列的线程池。因为对于固定大小的线程池而言，不存在线程数量的动态变化，因此 corePoolSize 和 maximumPoolSize 可以相等。同时，它
使用无界队列存放无法立即执行的任务，当任务提交非常频繁的时候，该队列可能迅速膨胀，从耗尽系统资源。

newSingleThreadExecutor() 方法返回的单线程线程池，是 newFixedThreadPool() 方法的一种退化，只是简单地将线程池数量设置为 1.

newCacheThreadPool()方法返回 corePoolSize 为0，maximumPoolSize  无穷大的线程池，这意味着在没有任务时，该线程池内无线程，而当
任务被提交时，该线程池会使用空闲的线程执行任务，若无空闲线程，则将任务加入 SynchronousQueue 队列，而 SychronousQueue 队列是一种直接
提交的队列，它总会迫使线程池增加新的线程执行任务。当任务执行完毕后，由于 corePoolSize 为 0 ， 因此空闲线程又会在指定时间内被回收。

对于 newCachedThreadPool()方法，如果同时有大量任务被提交，而任务的执行又不那么快时，那么系统便会开启等量的线程处理，这样做可能会耗尽
系统的资源。

# 5. 线程池拒绝策略

- AbortPolicy: 该策略直接抛出异常，阻止系统正常工作。
- CallerRunsPolicy 策略：只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。显然这样做不会真的丢弃任务，但是，任务提价线程
的性能极可能会急剧下降。
- DiscardOldestPolicy 策略：该策略将丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务。
- DiscardPolicy 策略：该策略默默地丢弃无法处理的任务，不予任何处理。

# 6. 有助于提高锁性能的几点建议

- 减少锁持有的时间：减少锁持有的时间有助于降低锁冲突的可能性，进而提高系统的并发能力。
- 减小锁粒度：所谓减小锁粒度，就是指缩小锁定对象的范围，从而降低锁冲突的可能性，进而提高系统的并发能力。
- 用读写分离锁来替换独占锁：在读多写少的场合使用读写锁可以有效提升系统的并发能力
- 锁分离
- 锁粗化：保证代码逻辑的情况下，如果再次进行减小锁粒度带来系统开销并没有取得相应的效果，就不要进行锁优化。

# 7. Java 虚拟机对锁优化所做的努力

在 JDK 内部也想尽一切办法提供并发时的系统吞吐量

### 7.1 锁偏向

锁偏向是一种针对加锁操作的优化手段。它的核心思想是：如果一个线程获得了锁，那么锁就进入了偏向模式。当这个线程再次请求锁时，
无须再做任何同步操作。这样接节省了大量有关锁申请的操作，从而提高了程序性能。因此，对于几乎没有所竞争的场合，偏向锁有比较好
的优化效果，因为连续多次极有可能是同一个线程请求相同的锁。而对于锁竞争比较激烈的场合，其效果不佳。因为在竞争激烈的场合，最
有可能的情况时每次都是不同的线程请求相同的锁。这样偏向锁模式会失效，因此还不如不启动偏向锁。使用 Java 虚拟机参数 
-XX:+UseBiasedLocking 可以开启偏向锁。

### 7.2 轻量级锁

如果偏向锁失败，那么虚拟机并不会立即挂起线程，它还会使用一种称为轻量级锁的优化手段。轻量级锁的操作也很方便，它只是简单地将对象
头部作为指针指向持有锁的线程堆栈的内部，来判断一个线程是否持有对象锁。如果线程获得轻量级锁成功，则可以顺利进入临界区。如果轻量
级锁加锁失败，则表示其他线程抢先争夺到了锁，那么当期线程的锁请求就会膨胀为重量级锁。

### 7.3 自旋锁

锁膨胀后，为了避免线程真实地在操作系统层面挂起，虚拟机还会做最后的努力 -- 自旋锁。当前线程暂时无法获得锁，而且什么时候可以获得
锁是一个未知数，也许在几个 CPU 四种周期后就可以得到锁。如果这样，简单粗暴地挂起线程可能是一种得不偿失的操作。系统会假设在不久的
将来，线程可以得到这把锁。因此，虚拟机会让当前线程做几个空循环，在经过若干次循环后，如果可以得到锁，那么久顺序进入临界区。如果还
不能获得锁，才会真的将线程在操作系统层面挂起。

### 7.4 锁消除

锁消除是一种更彻底的锁优化。Java 虚拟机在 JIT 编译时，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁。通过锁消除，可以节
省毫无意义的清秋锁时间。

如果不存在尽在，为什么程序员还要加上锁呢？这是因为在 Java 软件开发过程汇总，我们必然会使用一些JDK的内置API,比如StringBuffer,Vector等。
你在使用这些类的时候，也许根本不会考虑这些对象到底内部是如何实现的。

# 8. 无锁

对于并发控制而言，锁是一种悲观的策略。他总是假设每一次的临界区操作会产生冲突，因此，必须对每次操作小心翼翼。如果有多个线程同时需要访问
临界区资源，则宁可牺牲性能让线程进行等待，所以说锁会阻塞线程执行。而无锁是一种乐观的策略，它会假设会对资源的访问时没有冲突的。既然没有
冲突，自然不需要等待，所以所有的线程都可以在不停顿的状态下持续执行。那遇到冲突怎么办呢？无锁的策略使用一种叫作比较交换（CAS,Compare And 
Swap） 的技术来鉴别线程冲突，一旦检测到冲突产生，就重试当前操作直到没有冲突为止。

### 8.1 与众不同的锁并发策略：比较交换

与锁相比，使用比较交换会使程序看起来更加复杂一些，但由于其非阻塞性，它对死锁问题天生免疫，并且线程间的相互影响远远比基于锁的方式要小。更为
重要的是，使用无锁的方式完全没有锁竞争带来的系统开销，也没有线程间频繁调度带来的开销，因此，它要比基于锁的方式拥有更优越的性能。

CAS 算法的过程是：它包含三个参数 CAS(V,E,N)，其中 V 表示要更新的变量,E 表示预期值，N 表示新值。仅当 V 值等于 E 值时，才会将 V 的值设为 N,
如果 V 值和 E 值不同，说明已经有其他线程做了更新，则当前线程什么都不做。最后，CAS 放回当前 V 的真实值。CAS 操作是抱着乐观的态度进行的，它总是
认为自己可以成功完成操作。当多个线程同时使用 CAS 操作一个变量时，只有一个会胜出，并成功更新，其余均会失败。失败的线程不会被挂起，仅是被告知失败，
并且允许再次尝试，当然也允许失败的线程放弃操作。基于这样的原理，CAS 操作即使没有锁，也可以发现其他线程对当前线程的干扰，并进行恰当的处理。

简单地说，CAS 需要你额外给出一个期望值，也就是你认为这个变量现在应该是什么样子的。如果变量不是你想象的那样，则说明它已经被别人修改过了。你就重新
读取，再次尝试修改就好了。

在硬件层面，大部分的现代处理器都已经支持原子化的 CAS 指令。在 JDK 5 以后，虚拟机便可以使用这个指令来实现并发操作和并发数据结构，并且这种操作
在虚拟机可以说是无处不存的。

### 8.2 无锁的线程安全整数：AtomicInteger

### 8.3 无锁的引用对象：AtomicReference

AtomicReference 和 AtomicInteger 非常类似，不同之处就在于 AtomicInteger 是对整数的封装，而 AtomicReference 则是对应普通的对象引用。
也就是它可以保证你在修改对象引用时的线程安全性。在介绍 AtomicReference 的同时，我希望同时提出一个原子操作的逻辑上的不足。

之前我们说过，线程判断被修改对象是否可以正确写入的条件是对象的当前值和期望值是否一致。这个逻辑从一般意义上来说是正确的。但有可能出现一个小小
的例外，就是当你获得对象数据前后，在准备修改为新值前，对象的值被其他线程连续修改了两次，而经过这两次修改后，对象的值有恢复为旧值。这样，当前
线程就无法正确判断这个对象究竟是否被修改过。

![](http://xuweizhi.gitee.io/image/2019/09/09/CAS%20%E5%AF%B9%E8%B1%A1%E4%BF%AE%E6%94%B9.png)

一般来说，发生这种情况的概率很小，即使发生了，可能也不是什么大问题，比如，我们只是简单地要做一个数值加法，即使在取的期望值后，这个数字不断地被
修改，只要它最终改回了我的期望值，我的加法计算就不会出错。也就是说，当你修改的对象没有过程的状态信息时，所有的信息都只保存于对象的数值本身。

但是，在现实中，还可能存在另外一种场景，就是我们是否能修改对象的值，不仅取决于当前值，还和对象的过程变换有关，这是，AtomicReference 就无能为
力了。

打一个比方，有一家蛋糕店，为了挽留客服，决定为贵宾卡里余额小于 20 元的客服一次性赠送 20 元，刺激客服充值和消费，但条件是每一位客户只能被赠送
一次。

![](http://xuweizhi.gitee.io/image/2019/09/09/AtomicRefrence%20%E5%AF%B9%E8%B1%A1%E4%BB%A5%E5%90%8E%E7%94%A8.png)

### 带有时间戳的对象引用：AtomicStampedReference 

AtomicReference 无法解决上述问题的根本原因是，对象在修改过程汇总丢失了状态信息，对象值本身与状态被画上了等号。因此，我们只能够记录对象
在修改过程中的状态值，就可以很好地解决对象被反复修改导致线程无法正确判断对象状态的对象。

AtomicStampedReference 正是这么做的。它内部不仅维护了对象值,还维护了一个时间戳（我这里把它称为时间戳，实际上它可以使任何一个整数来表示状态值）。
当 AtomicStampedReference 对应的数值被修改时，除了更新数据本身外，还必须要更新时间戳。当 AtomicStampedReference 设置对象值时，对象值及时间戳
都必须满足期望值，写入才会成功。因此，即使对象值反复读写，写返回值，只要时间戳发生变化，就能防止不恰当的写入。






